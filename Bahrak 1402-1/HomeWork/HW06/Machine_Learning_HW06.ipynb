{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wgfc119e3B7I",
        "EPhXzTwWYeem",
        "js0Zvj-eu9hr",
        "gm2CdrJ6yfmg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 6\n",
        "Hi everyone this is your sixth homework.\n",
        "\n",
        "In this exercise, You will deal with **Unsupervised Learning**.\n",
        "\n",
        "You are free to discuss the problems and ways to approach them with your classmates, but be sure to not cheat. **Cheating will not be tolerated**."
      ],
      "metadata": {
        "id": "YrU5iOPu9fQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color=\"red\">**Question 1**</font>\n",
        "In this problem, you will generate simulated data, and then perform\n",
        "PCA and K-means clustering on the data."
      ],
      "metadata": {
        "id": "Wgfc119e3B7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Generate a simulated data set with 20 observations in each of three classes (i.e. 60 observations total), and 50 variables."
      ],
      "metadata": {
        "id": "pQyFyfbJ3IbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "# Your code:"
      ],
      "metadata": {
        "id": "opTUw0Jy3LQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Perform PCA on the 60 observations and plot the first two principal component score vectors. Use a different color to indicate the observations in each of the three classes. If the three classes appear separated in this plot, then continue on to part (c). If not, then return to part (a) and modify the simulation so that there is greater separation between the three classes. Do not continue to part (c) until the three classes show at least some separation in the first two principal component score vectors."
      ],
      "metadata": {
        "id": "rYk3z4rp30I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "McybG9Zm31Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Perform K-means clustering of the observations with K = 3. How well do the clusters that you obtained in K-means clustering compare to the true class labels?"
      ],
      "metadata": {
        "id": "c4fEaPQe35Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "yO-Aq4aL36YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Perform K-means clustering with K = 2. Describe your results."
      ],
      "metadata": {
        "id": "K2Csmk5839WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "GtKJxdrJ3_GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now perform K-means clustering with K = 4, and describe your results."
      ],
      "metadata": {
        "id": "KtvBQ9Gd4Ccm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "-fTVgRiz4DWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color=\"red\">**Question 2**</font>\n",
        "\n",
        "For a real world example, we will use **Bank Marketing Data Set dataset**. The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution.\n",
        "\n",
        "**Columns**\n",
        "1. age (numeric)\n",
        "2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5. default: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6. housing: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7. loan: has personal loan? (categorical: 'no','yes','unknown')\n",
        "\n",
        "**Related with the last contact of the current campaign:**\n",
        "8. contact: contact communication type (categorical: 'cellular','telephone')\n",
        "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', â€¦, 'nov', 'dec')\n",
        "10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "\n",
        "**Other attributes:**\n",
        "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
        "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "\n",
        "**Social and economic context attributes**\n",
        "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
        "17. cons.price.idx: consumer price index - monthly indicator (numeric)\n",
        "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
        "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
        "20. nr.employed: number of employees - quarterly indicator (numeric)\n",
        "21. subscribed : has the client subscribed a term deposit? (binary: 'yes','no')\n"
      ],
      "metadata": {
        "id": "EPhXzTwWYeem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Libarary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mping\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UT8_pJnnxbg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Exploratory Data Analysis - Preprocessing\n",
        "\n",
        "- let's try to undertand age distribution of customers."
      ],
      "metadata": {
        "id": "70DTJnlOG-MH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtA9VGX7wL44"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  see if there is between ages and loan status of customers."
      ],
      "metadata": {
        "id": "2FXwiw1_Htan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v56zgw_3Hz1P"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- try to undertand marital status distribution of customers."
      ],
      "metadata": {
        "id": "zeMaWfXnH3EO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUjJkv22Hz_w"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pdays column means number of days that passed by after the client was last contacted from a previous campaign. 999 means client was not previously contacted. look at that."
      ],
      "metadata": {
        "id": "rQMWzxkiIKk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btOFAIFQH0Gu"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t9cN-iy8INYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- look distribution of durations based on contact type"
      ],
      "metadata": {
        "id": "Q_6Ty6oLITe8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQkF6VTrH0KP"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- look loan status of customers."
      ],
      "metadata": {
        "id": "TFaJUOpXIWY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHivA8wSH0NR"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- look jobs, education customers"
      ],
      "metadata": {
        "id": "MkkfnIx6IZ_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z06SHmv-H0QC"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to calculate distances for K-Means clustering, all features must be in numeric format. solve this issue and then apply scaling"
      ],
      "metadata": {
        "id": "CudctVKYIZVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRFzqZHzH0TZ"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use kmeans and fit the model"
      ],
      "metadata": {
        "id": "-AuhWEW5Ixo6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY2e_kZMIxo7"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- correlations of each feature with clusters that you assigned."
      ],
      "metadata": {
        "id": "ysrDth17I-PB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6g12gdXJBM7"
      },
      "outputs": [],
      "source": [
        "# Your code:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- How to find optimal number of clusters (K)?"
      ],
      "metadata": {
        "id": "rU8Q01BRJKVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\">**Answer:**</font>"
      ],
      "metadata": {
        "id": "WciHZ9pXaue4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "iuKZvH4kJcub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN (Density-based spatial clustering)\n",
        "\n",
        "**DBSCAN**, which stands for Density-Based Spatial Clustering of Applications with Noise, is a clustering algorithm used in machine learning and data mining. Unlike k-means, DBSCAN does not require the user to specify the number of clusters beforehand and can identify clusters of arbitrary shapes. It is particularly effective in discovering clusters in data with varying densities.\n",
        "\n",
        "Here are the main concepts associated with DBSCAN:\n",
        "\n",
        "**Core Points:**\n",
        "A data point is considered a core point if there are at least a specified number of data points (minPts) within a certain radius (eps) around it, including itself.\n",
        "\n",
        "**Border Points:** A data point is a border point if it is within the specified radius of a core point but does not have enough neighbors to be considered a core point itself.\n",
        "\n",
        "**Noise:** Data points that are neither core points nor border points are considered noise. They do not belong to any cluster.\n",
        "\n",
        "The DBSCAN algorithm works as follows:\n",
        "\n",
        "1. **Select a Random Unvisited Data Point:**\n",
        "Choose a data point that has not been visited.\n",
        "2. **Expand Cluster:**\n",
        "If the chosen point is a core point, create a new cluster and expand it by adding all reachable core points (and their neighbors) to the cluster.\n",
        "3. **Repeat:**\n",
        "Continue the process until all points have been visited.\n",
        "The result is a set of clusters, each containing core points that are densely connected. Border points may be part of a cluster but are not as tightly connected as core points. Noise points are not assigned to any cluster.\n",
        "\n",
        "The DBSCAN algorithm uses two parameters:\n",
        "\n",
        "**eps (Îµ):** A distance measure that will be used to locate the points in the neighborhood of any point. For each instance, the algorithm counts how many instances are located within a small distance Îµ (epsilon) from it. This region is called the instanceâ€™s Îµ-neighborhood.\n",
        "\n",
        "**minPts:** The minimum number of points (a threshold) clustered together for a region to be considered dense. If an instance has at least min_samples instances in its Îµ-neighborhood (including itself), then it is considered a core instance. In other words, core instances are those that are located in dense regions. All instances in the neighborhood of a core instance belong to the same cluster. This neighborhood may include other core instances; therefore, a long sequence of neighboring core instances forms a single cluster.\n",
        "\n",
        "Any instance that is not a core instance and does not have one in its neighborhood is considered an anomaly.\n",
        "\n",
        "To check out more, please visit [this](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/) online visualisation tool."
      ],
      "metadata": {
        "id": "HXNJZCv8pxNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color=\"red\">**Question 3**</font>\n",
        "For a real world example, we will use **Wholesale customers dataset**. The data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories. It can be downloaded from [here](https://archive.ics.uci.edu/dataset/292/wholesale+customers).\n",
        "\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1. **FRESH:** annual spending (m.u.) on fresh products (Continuous);\n",
        "2. **MILK:** annual spending (m.u.) on milk products (Continuous);\n",
        "3. **GROCERY:** annual spending (m.u.)on grocery products (Continuous);\n",
        "4. **FROZEN:** annual spending (m.u.)on frozen products (Continuous)\n",
        "5. **DETERGENTS_PAPER:** annual spending (m.u.) on detergents and paper products (Continuous)\n",
        "6. **DELICATESSEN:** annual spending (m.u.)on and delicatessen products (Continuous);\n",
        "7. **CHANNEL:** customers  Channel - Horeca (Hotel/Restaurant/CafÃƒÂ©) or Retail channel (Nominal)\n",
        "8. **REGION:** customers  Region Lisnon, Oporto or Other (Nominal)\n"
      ],
      "metadata": {
        "id": "6szonmC9rgUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Do exploratory data analysis and preprocessing\n",
        "\n",
        "- Showing the relation between *MILK* and *GROCERY* spending\n",
        "\n",
        "- create an annotated clustermap of the correlations between spending on different categories"
      ],
      "metadata": {
        "id": "CeD_PRBmsSIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "tdz86qhsswSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a variety of models testing different epsilon values."
      ],
      "metadata": {
        "id": "w5nhqua7s0I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "GnvWQFqbs9ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Based on the plot that you had from the last part, retrain a DBSCAN model with a reasonable epsilon value"
      ],
      "metadata": {
        "id": "jQ0Ji2ADtLHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "MAyKEJYNtSkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image segmentation\n",
        "\n",
        "\n",
        "Image segmentation is a computer vision task that involves dividing an image into meaningful and semantically coherent regions or segments. The goal is to partition an image into regions that share similar visual characteristics, such as color, texture, intensity, or other features. Each segment typically represents a distinct object or region of interest within the image."
      ],
      "metadata": {
        "id": "VM1XHuuFu73C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color=\"red\">**Question 4**</font>\n",
        "In this question, you are supposed to segmente an image using KMeans clustering.\n"
      ],
      "metadata": {
        "id": "js0Zvj-eu9hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import load_sample_image\n",
        "#load_sample_image dataset from scikit learn consists of numpy array of a single sample image\n",
        "\n",
        "#Data plotting and visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "id": "nsoiXXSqvfIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load a sample flower image from load_sample_image scikit learn dataset and show the image\n"
      ],
      "metadata": {
        "id": "3R-wYyqlvkoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flower = load_sample_image(\"flower.jpg\")\n",
        "# Your code:"
      ],
      "metadata": {
        "id": "Hr6-XdnqvnU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Get shape, scale, reshape"
      ],
      "metadata": {
        "id": "tmrtGctyv1bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "ywu1x3WNwPav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use KMeans clustering and get the different colored images\n"
      ],
      "metadata": {
        "id": "7bI_sRxjwQ25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "urjxStKpwnTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian Mixture Model\n",
        "\n",
        "**Gaussian Mixture Model** (GMM) is a probabilistic model that represents a mixture of multiple Gaussian (normal) distributions. Each component Gaussian distribution in the mixture represents a cluster or a subpopulation within the overall dataset. GMMs are commonly used for modeling complex probability distributions and are frequently applied in the field of machine learning, particularly in unsupervised learning tasks such as clustering and density estimation."
      ],
      "metadata": {
        "id": "S68r9p_2yfme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color=\"red\">**Question 5**</font>\n",
        "To deal with GMM, we will use **CC GENERAL** dataset.\n",
        "\n",
        "Following is the Data Dictionary for Credit Card dataset :\n",
        "\n",
        "- **CUST_ID** : Identification of Credit Card holder (Categorical)\n",
        "- **BALANCE** : Balance amount left in their account to make purchases\n",
        "- **BALANCE_FREQUENCY** : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n",
        "- **PURCHASES** : Amount of purchases made from account\n",
        "- **ONEOFF_PURCHASES** : Maximum purchase amount done in one-go\n",
        "- **INSTALLMENTS_PURCHASES** : Amount of purchase done in installment\n",
        "- **CASH_ADVANCE** : Cash in advance given by the user\n",
        "- **PURCHASES_FREQUENCY** : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n",
        "- **ONEOFFPURCHASESFREQUENCY** : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n",
        "PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n",
        "- **CASHADVANCEFREQUENCY** : How frequently the cash in advance being paid\n",
        "- **CASHADVANCETRX** : Number of Transactions made with \"Cash in Advanced\"\n",
        "- **PURCHASES_TRX** : Numbe of purchase transactions made\n",
        "- **CREDIT_LIMIT** : Limit of Credit Card for user\n",
        "- **PAYMENTS** : Amount of Payment done by user\n",
        "- **MINIMUM_PAYMENTS** : Minimum amount of payments made by user\n",
        "- **PRCFULLPAYMENT** : Percent of full payment paid by user\n",
        "- **TENURE** : Tenure of credit card service for user\n"
      ],
      "metadata": {
        "id": "gm2CdrJ6yfmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import DataFrame\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "tpusvy64z3V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load dataset"
      ],
      "metadata": {
        "id": "I6DOKez8z3_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "qzOYn860z-yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Standardize data, Normalize and Reduce the dimensions of the data"
      ],
      "metadata": {
        "id": "F4BUbh7B0AhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "DbARC3CL0AhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use Gaussian Mixture Model"
      ],
      "metadata": {
        "id": "ZzPcnbpc0A1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "Lfk6bIGD0A1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Visualize the clustering and analyse"
      ],
      "metadata": {
        "id": "3XiS34D50BAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code:"
      ],
      "metadata": {
        "id": "T38-u9_90BAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}