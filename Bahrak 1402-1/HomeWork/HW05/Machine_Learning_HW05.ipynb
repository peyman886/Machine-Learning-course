{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size='+1' color=red>**Attention:**</font> Data cleaning and other parts of preprocessing of data which we covered in the first assignment, is not neccesary all the time but you may need some of them according to task at hand. So we don't explicitly mention them each time. This is your job to figure out when to apply them.\n",
        "\n",
        "<font size='+1' color=red>**Attention 2:**</font> For your implementations always use `random_state=42` so your code would be reproducible."
      ],
      "metadata": {
        "id": "xvYT4kv1TQpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q1:**</font> <font size='+2'> **PCA for Classification** </font>\n",
        "\n",
        "In this question we want to work with the Fashion-MNIST dataset. Fashion-MNIST is a dataset comprising of $28 \\times 28$ grayscale images of $70,000$ fashion products from $10$ categories, with $7,000$ images per category. The training set has $60,000$ images and the test set has $10,000$ images. <br>\n",
        "<font color=red>**Note:**</font> You can download it from any source you want. <br>\n",
        "<font color=red>**Note:**</font> Take first $60,000$ instances of it as the train and the $10,000$ remaining instances as the test set.\n",
        "\n",
        "Using explained varinace ratio and considering a threshold like $95\\%$ you probably know how to choose the right number of dimensions to perform PCA. But, when you are using dimensionality reduction as a preprocessing step for a supervised learning task, it is important to consider the impact of the optimal number of dimensions on the overall performance of the model. Consider the classification task using the dataset at hand. Try to find the best number of components for the PCA with respect to the task. You should use the `RandomForestClassifier`, `KNeighborsClassifier`, `DecisionTreeClassifier`, and `AdaBoostClassifier`. Compare your results (number of dimensions, accuracy, precision, recall, f1-score, and confusion matrix) and explain why the number of dimensions for different models are different. Don't forget to analyze your results. [Hint: you should try to make a pipeline and try to tune the hyperparameters of PCA and your model adjointly.]\n",
        "\n",
        "At the end, perform the hyperparameter tuning but this time without considering the PCA preprocessing step. Compare your results with previous ones."
      ],
      "metadata": {
        "id": "PvVpPcQSYpJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A1:**</font>\n",
        "### Approach Summary\n",
        "\n",
        "1. **Data Loading and Splitting**:\n",
        "   - The Fashion-MNIST dataset was loaded using `fetch_openml`.\n",
        "   - The dataset was split into a training set (first 60,000 instances) and a test set (last 10,000 instances).\n",
        "\n",
        "2. **Classifier Setup**:\n",
        "   - Four classifiers were chosen for this task: `RandomForestClassifier`, `KNeighborsClassifier`, `DecisionTreeClassifier`, and `AdaBoostClassifier`.\n",
        "   - Each classifier was used in conjunction with PCA in a pipeline.\n",
        "\n",
        "3. **Hyperparameter Tuning**:\n",
        "   - `RandomizedSearchCV` was employed to tune the hyperparameters of both PCA and the classifiers.\n",
        "   - Different ranges and values for hyperparameters were specified for each classifier.\n",
        "\n",
        "4. **Model Evaluation**:\n",
        "   - After training, each model was evaluated on the test set.\n",
        "   - Performance metrics included accuracy, precision, recall, f1-score, and confusion matrix.\n",
        "\n",
        "5. **Results Compilation**:\n",
        "   - The best parameters found, along with the performance metrics for each classifier, were compiled into a DataFrame and saved to a CSV file.\n"
      ],
      "metadata": {
        "id": "NCoy1uNHM-cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Load the dataset\n",
        "fashion_mnist = fetch_openml('Fashion-MNIST', version=1)\n",
        "X = fashion_mnist.data\n",
        "y = fashion_mnist.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "metadata": {
        "id": "HiiEKQuca4bU",
        "outputId": "1dbb2a11-a491-47de-e87e-0a9b903ca21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifiers and hyperparameter distributions\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(random_state=42),\n",
        "    'KNeighbors': KNeighborsClassifier(),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "param_distributions = {\n",
        "    'RandomForest': {\n",
        "        'clf__n_estimators': randint(50, 200),\n",
        "        'clf__max_depth': randint(3, 10),\n",
        "        'pca__n_components': [0.90, 0.95, 0.99]\n",
        "    },\n",
        "    'KNeighbors': {\n",
        "        'clf__n_neighbors': randint(3, 10),\n",
        "        'pca__n_components': [0.90, 0.95, 0.99]\n",
        "    },\n",
        "    'DecisionTree': {\n",
        "        'clf__max_depth': randint(3, 10),\n",
        "        'pca__n_components': [0.90, 0.95, 0.99]\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'clf__n_estimators': randint(50, 100),\n",
        "        'pca__n_components': [0.90, 0.95, 0.99]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Xga6JiDwMjam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results DataFrame\n",
        "results_df = pd.DataFrame()\n",
        "\n",
        "# Loop over classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('pca', PCA()),\n",
        "        ('clf', clf)\n",
        "    ])\n",
        "\n",
        "    random_search = RandomizedSearchCV(pipeline, param_distributions[name],\n",
        "                                       n_iter=5, cv=3, scoring='accuracy',\n",
        "                                       random_state=42, n_jobs=-1)\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = random_search.best_params_\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Save results\n",
        "    results_df = results_df.append({\n",
        "        'Classifier': name,\n",
        "        'Best Params': best_params,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Confusion Matrix': conf_matrix\n",
        "    }, ignore_index=True)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('classifier_performance.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv7yKQPAK2xZ",
        "outputId": "1198a4f7-86c3-49b8-e24c-11fa11d90aa6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-3e648fbe8350>:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-2-3e648fbe8350>:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-2-3e648fbe8350>:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-2-3e648fbe8350>:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "O0XHCyxkNzU_",
        "outputId": "cf53ad11-b23e-42ac-e37f-59899e9021f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3c899ad3fe5e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's analyze the results from the `classifier_performance.csv` file to understand how the PCA affected different classifiers and derive insights based on accuracy, precision, recall, f1-score, and confusion matrices.\n",
        "\n",
        "### Interpretation of Results\n",
        "\n",
        "1. **Random Forest Classifier**\n",
        "   - **Best Parameters**: Maximum depth of 9 and 142 estimators with a PCA component ratio of 0.95.\n",
        "   - **Performance**:\n",
        "     - Accuracy: 81.11%\n",
        "     - Precision: 80.70%\n",
        "     - Recall: 81.11%\n",
        "     - F1 Score: 80.65%\n",
        "   - **Analysis**: The Random Forest Classifier performed well, balancing accuracy and complexity. The choice of PCA components shows a preference for a relatively high-dimensional feature space, which is suitable for capturing the complex decision boundaries in the data.\n",
        "\n",
        "2. **K-Neighbors Classifier**\n",
        "   - **Best Parameters**: 7 neighbors with a PCA component ratio of 0.90.\n",
        "   - **Performance**:\n",
        "     - Accuracy: 86.01%\n",
        "     - Precision: 86.07%\n",
        "     - Recall: 86.01%\n",
        "     - F1 Score: 85.95%\n",
        "   - **Analysis**: The K-Neighbors Classifier outperformed the other models in terms of accuracy. The lower number of PCA components suggests that it can work well even in a reduced feature space, likely due to the nature of K-Neighbors being sensitive to distances in fewer dimensions.\n",
        "\n",
        "3. **Decision Tree Classifier**\n",
        "   - **Best Parameters**: Maximum depth of 9 with a PCA component ratio of 0.90.\n",
        "   - **Performance**:\n",
        "     - Accuracy: 72.74%\n",
        "     - Precision: 74.16%\n",
        "     - Recall: 72.74%\n",
        "     - F1 Score: 72.46%\n",
        "   - **Analysis**: The Decision Tree Classifier showed moderate performance. The decision tree's structure may lose some effectiveness when the data dimensionality is reduced, as it relies on splitting the feature space which can be more informative in higher dimensions.\n",
        "\n",
        "4. **AdaBoost Classifier**\n",
        "   - **Best Parameters**: 57 estimators with a PCA component ratio of 0.95.\n",
        "   - **Performance**:\n",
        "     - Accuracy: 55.67%\n",
        "     - Precision: 55.66%\n",
        "     - Recall: 55.67%\n",
        "     - F1 Score: 54.60%\n",
        "   - **Analysis**: AdaBoost had the lowest performance among the classifiers. This might indicate that the combination of PCA and AdaBoost is not as effective for this dataset, possibly due to the way AdaBoost focuses on misclassified instances which might not align well with the PCA-transformed feature space.\n",
        "\n",
        "### General Observations\n",
        "\n",
        "- The optimal number of PCA components varied across classifiers, indicating that different models have different capabilities and preferences in handling the dimensionality of the feature space.\n",
        "- Classifiers like K-Neighbors benefited from dimensionality reduction, likely due to its reliance on distance calculations, which can become more meaningful in a lower-dimensional space.\n",
        "- More complex models like Random Forest and AdaBoost seemed to require a higher-dimensional space, possibly to capture more complex decision boundaries.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The experiment highlights the importance of considering the interaction between feature extraction techniques like PCA and the choice of classifier. The varying performance across different classifiers with different PCA settings underscores the need for careful hyperparameter tuning and model selection based on the characteristics of the dataset and the models' inherent properties."
      ],
      "metadata": {
        "id": "cRrENFdACWkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q2:**</font> <font size='+2'> **Randomized PCA** </font>\n",
        "\n",
        "In this question we want to check the time complexity of finding an approximation of the first $d$ principal components. Also, we want to see how is the performance of it in compare to the original PCA. In order to make this happen there is a stochastic algorithm called *randomized PCA* which has a faster procedure to find the first $d$ principal components.\n",
        "\n",
        "By default, the `svd_solver` parameter of PCA in Scikit-learn is set to `\"auto\"`. It means that it automatically determine to use `\"full\"` or `\"randomized\"` to find the principal components. Base on our text book:\n",
        "\n",
        "\"Scikit-learn uses the randomized PCA algorithm if $max(m, n) > 500$ and `n_components` is an integer smaller than $80\\%$ of $min(m,n)$, or else it uses the full SVD approach\"\n",
        "\n",
        "<font size='+1'>**(a)**</font> For previous question you found $d$ components for each one of the classifiers. This time try to perform PCA without considering the classifier and just by determining the number of components. For the `svd_solver`, this time use both `\"full\"` and `\"randomized\"` arguments separately and compare the results of them. Also compare the running time of `\"full\"` and `\"randomized\"` for each one of the classifiers. Explain your observations.\n",
        "\n",
        "<font size='+1'>**(b)**</font> This time consider the $d=10$ and compare the running times for both `\"full\"` and `\"randomized\"` arguments. Explain your observations.\n",
        "\n",
        "<font size='+1'>**(c)**</font> There is something called Incremental PCA (IPCA), explain what is it and in what situations it is useful?\n",
        "\n",
        "<font size='+1'>**(d)**</font> Consider the number of batches equal to $200$ and perform the IPCA."
      ],
      "metadata": {
        "id": "TQc4j8JMWdx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A2:**</font> Your explanations"
      ],
      "metadata": {
        "id": "Z9C3GhsyDVib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import time\n",
        "\n",
        "\n",
        "# Number of components\n",
        "n_components = 50\n",
        "\n",
        "# PCA with svd_solver='full'\n",
        "start_time = time.time()\n",
        "pca_full = PCA(n_components=n_components, svd_solver='full')\n",
        "pca_full.fit(X_train)\n",
        "full_time = time.time() - start_time\n",
        "print(f\"Time taken for 'full' PCA: {full_time:.2f} seconds\")\n",
        "\n",
        "# PCA with svd_solver='randomized'\n",
        "start_time = time.time()\n",
        "pca_randomized = PCA(n_components=n_components, svd_solver='randomized')\n",
        "pca_randomized.fit(X_train)\n",
        "randomized_time = time.time() - start_time\n",
        "print(f\"Time taken for 'randomized' PCA: {randomized_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "Iob5574QDTvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q3:**</font> <font size='+2'> **Locally Linear Embedding** </font>\n",
        "\n",
        "Locally linear embedding (LLE), is a nonlinear dimensionality reduction algorithm which is categorized as a manifold learning technique.\n",
        "\n",
        "<font size='+1'>**(a)**</font> At first, try to explain how it works by mentioning its optimization objectives.\n",
        "\n",
        "<font size='+1'>**(b)**</font> Now, it's time to implement it and trying to perform your implementation on a swiss roll to see what happens after unrolling. (try to plot your results)\n",
        "The code below make you a swiss roll with $1000$ samples.\n",
        "\n",
        "<font size='+1'>**(c)**</font> Finally use the LLE implementation provided by Scikit-learn to check the results of your implementation. (plot your results)"
      ],
      "metadata": {
        "id": "JfezDIMqW_OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A3:**</font> Your explanations"
      ],
      "metadata": {
        "id": "lhJB7JkmEvTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_swiss_roll\n",
        "\n",
        "X_swiss, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ot2rwJlSW-Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "3gcIzPzZEJm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q4:**</font> <font size='+2'> **t-SNE vs. UMAP ‎️‍🔥** </font>\n",
        "\n",
        "In this question we need the first $5000$ images of Fashion-MNIST dataset. We want to reduce the dimension of these samples down to 2 so we can plot them. Here, we use t-SNE and UMAP to perform these reductions. You can use scatterplot with 10 different colors to demonstrate the class of each instance. After visulaization try to analyze your results and compare them with each other. Is there any pattern in these visualizations?"
      ],
      "metadata": {
        "id": "MlITuQBUiohI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A4:**</font> Your explanations"
      ],
      "metadata": {
        "id": "aOpTYSRME1jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "aVh8hnxZvl3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q5:**</font> <font size='+2'> **Iris** </font>\n",
        "\n",
        "You will take a shortcut and load the Iris dataset from Scikit-learn’s datasets module. Furthermore, you will only select two features, sepal width and petal length, to make the classification task more challenging for illustration purposes"
      ],
      "metadata": {
        "id": "Fd_-f0gjp5bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-4_nATDzrl28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "yoODjVwHrv_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the Iris examples into 50 percent training and 50 percent test data:"
      ],
      "metadata": {
        "id": "srxliDlC4lFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "eRWmkBhYsizR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the training dataset, you now will train three different classifiers:\n",
        "\n",
        "- Logistic regression classifier\n",
        "\n",
        "- Decision tree classifier\n",
        "\n",
        "- k-nearest neighbors classifier\n",
        "\n",
        "you will then evaluate the model performance of each classifier via 10-fold cross-validation on the training dataset before combining them into an ensemble classifier:"
      ],
      "metadata": {
        "id": "0Le3UZmU4oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "iYd5PyN9rxsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q6:**</font> <font size='+2'> **Carseats** </font>\n",
        "\n",
        "#### Ensemble Learning\n",
        "\n",
        "Ensemble learning is a machine learning technique that involves combining the predictions of multiple models to improve the overall performance and accuracy of a system. Instead of relying on a single model to make predictions, ensemble methods use a group of models and aggregate their predictions to achieve better results than any individual model could achieve on its own.\n",
        "\n",
        "The basic idea behind ensemble learning is that by combining the strengths of different models, it is possible to mitigate the weaknesses of each individual model. Ensemble methods are often used to enhance predictive accuracy, reduce overfitting, and improve the robustness of the model.\n",
        "\n",
        "There are several popular ensemble learning techniques, including:\n",
        "\n",
        "**Bagging (Bootstrap Aggregating):** This method involves training multiple instances of the same learning algorithm on different subsets of the training data, typically created by random sampling with replacement. The predictions of these models are then averaged or voted upon to make the final prediction.\n",
        "\n",
        "**Boosting:** Boosting focuses on training a sequence of weak learners, where each subsequent model corrects the errors of its predecessor. Popular boosting algorithms include AdaBoost (Adaptive Boosting) and Gradient Boosting.\n",
        "\n",
        "**Random Forest:** Random Forest is an ensemble method based on bagging. It constructs multiple decision trees during training and combines their predictions through averaging or voting. Each tree in the forest is trained on a random subset of the features.\n",
        "\n",
        "Stacking: Stacking involves training multiple diverse models and using another model (meta-model or blender) to combine their predictions. The predictions of individual models serve as input features for the meta-model.\n",
        "\n",
        "Ensemble learning is a powerful technique that is widely used in various machine learning applications. It is particularly effective when dealing with complex and diverse datasets, as well as when individual models may have different strengths and weaknesses."
      ],
      "metadata": {
        "id": "N0o_08_dpydx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to work with **Carseats** dataset. We want to predict the sales using regression trees and related approaches, treating the response as a quantitative variable."
      ],
      "metadata": {
        "id": "piAQAOuOpijJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load Dataset"
      ],
      "metadata": {
        "id": "1mzLGdm4pwKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz"
      ],
      "metadata": {
        "id": "oym5JLQdcy11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Do preprocess\n",
        "- Split the data set into a training set and a test set."
      ],
      "metadata": {
        "id": "44HOtayap3Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code:"
      ],
      "metadata": {
        "id": "xFVYdiZeqRoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fit a regression tree to the training set. Plot the tree, and interpret\n",
        "the results. What test MSE do you obtain?"
      ],
      "metadata": {
        "id": "ReN9KAYBqUqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "dromxeOMq3Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use the bagging approach in order to analyze this data. What test MSE do you obtain? which variables are most important. visualize them"
      ],
      "metadata": {
        "id": "LAkQPtSfr1JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "MWOPM20ErVMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use random forests to analyze this data. What test MSE do you obtain?  which variables are most important. Describe the effect of m, the number of variables considered at each split, on the error rate obtained."
      ],
      "metadata": {
        "id": "HgADUcGXsSmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "x7ajvS2BrXxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}