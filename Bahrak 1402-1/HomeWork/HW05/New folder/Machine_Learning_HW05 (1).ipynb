{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size='+1' color=red>**Attention:**</font> Data cleaning and other parts of preprocessing of data which we covered in the first assignment, is not neccesary all the time but you may need some of them according to task at hand. So we don't explicitly mention them each time. This is your job to figure out when to apply them.\n",
        "\n",
        "<font size='+1' color=red>**Attention 2:**</font> For your implementations always use `random_state=42` so your code would be reproducible."
      ],
      "metadata": {
        "id": "xvYT4kv1TQpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q1:**</font> <font size='+2'> **PCA for Classification** </font>\n",
        "\n",
        "In this question we want to work with the Fashion-MNIST dataset. Fashion-MNIST is a dataset comprising of $28 \\times 28$ grayscale images of $70,000$ fashion products from $10$ categories, with $7,000$ images per category. The training set has $60,000$ images and the test set has $10,000$ images. <br>\n",
        "<font color=red>**Note:**</font> You can download it from any source you want. <br>\n",
        "<font color=red>**Note:**</font> Take first $60,000$ instances of it as the train and the $10,000$ remaining instances as the test set.\n",
        "\n",
        "Using explained varinace ratio and considering a threshold like $95\\%$ you probably know how to choose the right number of dimensions to perform PCA. But, when you are using dimensionality reduction as a preprocessing step for a supervised learning task, it is important to consider the impact of the optimal number of dimensions on the overall performance of the model. Consider the classification task using the dataset at hand. Try to find the best number of components for the PCA with respect to the task. You should use the `RandomForestClassifier`, `KNeighborsClassifier`, `DecisionTreeClassifier`, and `AdaBoostClassifier`. Compare your results (number of dimensions, accuracy, precision, recall, f1-score, and confusion matrix) and explain why the number of dimensions for different models are different. Don't forget to analyze your results. [Hint: you should try to make a pipeline and try to tune the hyperparameters of PCA and your model adjointly.]\n",
        "\n",
        "At the end, perform the hyperparameter tuning but this time without considering the PCA preprocessing step. Compare your results with previous ones."
      ],
      "metadata": {
        "id": "PvVpPcQSYpJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A1:**</font>"
      ],
      "metadata": {
        "id": "8rOUtFP1DHAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import Necessary Libraries\n"
      ],
      "metadata": {
        "id": "yuEirALGZoia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# from scipy.stats import randint"
      ],
      "metadata": {
        "id": "Ryc62iG4ZfJ9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Load the Dataset"
      ],
      "metadata": {
        "id": "YeFCAEXPZ0BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "fashion_mnist = fetch_openml('Fashion-MNIST', version=1)\n",
        "X = fashion_mnist.data\n",
        "y = fashion_mnist.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "metadata": {
        "id": "g1tGNFcUWfVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a13ba2-2adb-4c99-cb0b-fd295b4a0c8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Define the Pipelines and Parameters for Grid Search"
      ],
      "metadata": {
        "id": "1aB3QaZJZ4yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = {\n",
        "    'rf': Pipeline([('pca', PCA()), ('classifier', RandomForestClassifier(random_state=42))]),\n",
        "    'knn': Pipeline([('pca', PCA()), ('classifier', KNeighborsClassifier())]),\n",
        "    'dt': Pipeline([('pca', PCA()), ('classifier', DecisionTreeClassifier(random_state=42))]),\n",
        "    'ada': Pipeline([('pca', PCA()), ('classifier', AdaBoostClassifier(random_state=42))])\n",
        "}\n",
        "\n",
        "param_grid = {\n",
        "    'rf': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__n_estimators': [100, 200]},\n",
        "    'knn': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__n_neighbors': [3, 5, 7]},\n",
        "    'dt': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__max_depth': [10, 20, 30]},\n",
        "    'ada': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__n_estimators': [50, 100]}\n",
        "}\n"
      ],
      "metadata": {
        "id": "Vaj9v_ZVZlIH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Train and Evaluate Each Model"
      ],
      "metadata": {
        "id": "8BZ6F525Z-zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    # grid_search = GridSearchCV(pipeline, param_grid[name], cv=5, scoring='accuracy')\n",
        "    grid_search = RandomizedSearchCV(pipeline, param_grid[name], n_iter=5, cv=5, verbose=1, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    predictions = best_model.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        'Best Parameters': grid_search.best_params_,\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Confusion Matrix': confusion_matrix(y_test, predictions)\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "for model, metrics in results.items():\n",
        "    print(f\"Model: {model}\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "d4iNu_LTaEcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Analysis"
      ],
      "metadata": {
        "id": "z-9osEWuYd-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RandomForestClassifier (rf)\n",
        "- **PCA Components**: 0.9\n",
        "- **Accuracy**: 0.8624\n",
        "- **Precision**: 0.8609\n",
        "- **Recall**: 0.8624\n",
        "- **F1 Score**: 0.8608\n",
        "\n",
        "**Analysis**: RandomForest performed well with a PCA component setting of 0.9. This indicates that capturing 90% of the variance in the data is sufficient for a complex ensemble method like RandomForest, which can handle a higher dimensional space effectively. The high accuracy and balanced precision-recall suggest that RandomForest is able to classify most classes accurately.\n",
        "\n",
        "#### KNeighborsClassifier (knn)\n",
        "- **PCA Components**: 0.95\n",
        "- **Accuracy**: 0.8623\n",
        "- **Precision**: 0.8631\n",
        "- **Recall**: 0.8623\n",
        "- **F1 Score**: 0.8616\n",
        "\n",
        "**Analysis**: KNN needed slightly more features (95% variance) to achieve similar performance to RandomForest. This is understandable as KNN relies heavily on the feature space for making decisions based on the nearest neighbors. The slight increase in the number of dimensions may provide more distinctiveness between different classes for KNN.\n",
        "\n",
        "#### DecisionTreeClassifier (dt)\n",
        "- **PCA Components**: 0.85\n",
        "- **Accuracy**: 0.7753\n",
        "- **Precision**: 0.7770\n",
        "- **Recall**: 0.7753\n",
        "- **F1 Score**: 0.7760\n",
        "\n",
        "**Analysis**: The DecisionTreeClassifier performed best with 85% variance, which is lower than the others. This might be because decision trees can overfit with too many features. A reduced feature set can sometimes help in preventing the model from fitting to noise in the data.\n",
        "\n",
        "#### AdaBoostClassifier (ada)\n",
        "- **PCA Components**: 0.95\n",
        "- **Accuracy**: 0.5746\n",
        "- **Precision**: 0.5769\n",
        "- **Recall**: 0.5746\n",
        "- **F1 Score**: 0.5626\n",
        "\n",
        "**Analysis**: AdaBoost with 95% variance components had the lowest performance among the models. AdaBoost is sensitive to noisy data and outliers, and the higher dimensional space might be introducing more complexity than the model can handle effectively.\n",
        "\n",
        "\n",
        "#### **Overall Observation**\n",
        "Different models require a different number of PCA components because each model has a unique way of handling and interpreting features. Models like RandomForest and KNN can benefit from a higher dimensional space as they can capture more complex patterns, while simpler models like DecisionTrees might perform better with fewer dimensions to prevent overfitting.\n",
        "\n",
        "The varying performance across models also highlights the importance of considering both the model's nature and the feature space's dimensionality when performing tasks like classification. The results also demonstrate the utility of PCA in reducing dimensionality while preserving enough information for effective model training and prediction."
      ],
      "metadata": {
        "id": "3CeQ7wRXYUDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. tuning without considering the PCA preprocessing step"
      ],
      "metadata": {
        "id": "AjVeOqHGaB8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    'rf': RandomForestClassifier(random_state=42),\n",
        "    'knn': KNeighborsClassifier(),\n",
        "    'dt': DecisionTreeClassifier(random_state=42),\n",
        "    'ada': AdaBoostClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "param_grid_no_pca = {\n",
        "    'rf': {'n_estimators': [100, 200]},\n",
        "    'knn': {'n_neighbors': [3, 5, 7]},\n",
        "    'dt': {'max_depth': [10, 20, 30]},\n",
        "    'ada': {'n_estimators': [50, 100]}\n",
        "}"
      ],
      "metadata": {
        "id": "fMWlc_UlaTXN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_no_pca = {}\n",
        "for name, classifier in classifiers.items():\n",
        "    grid_search_no_pca = RandomizedSearchCV(classifier, param_grid_no_pca[name],\n",
        "                                            scoring='accuracy', n_iter=5, cv=5, verbose=1, n_jobs=-1)\n",
        "    grid_search_no_pca.fit(X_train, y_train)\n",
        "\n",
        "    best_model_no_pca = grid_search_no_pca.best_estimator_\n",
        "    predictions_no_pca = best_model_no_pca.predict(X_test)\n",
        "\n",
        "    results_no_pca[name] = {\n",
        "        'Best Parameters': grid_search_no_pca.best_params_,\n",
        "        'Accuracy': accuracy_score(y_test, predictions_no_pca),\n",
        "        'Precision': precision_score(y_test, predictions_no_pca, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions_no_pca, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions_no_pca, average='macro'),\n",
        "        'Confusion Matrix': confusion_matrix(y_test, predictions_no_pca)\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "for model, metrics in results_no_pca.items():\n",
        "    print(f\"Model: {model}\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "a992MUgPaXpO",
        "outputId": "0ca786db-f3d8-490e-939f-77ce33eb45cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5e40b756126a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     grid_search_no_pca = RandomizedSearchCV(classifier, param_grid_no_pca[name],\n\u001b[1;32m      4\u001b[0m                                             scoring='accuracy', n_iter=5, cv=5, verbose=1, n_jobs=-1)\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgrid_search_no_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbest_model_no_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_no_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q2:**</font> <font size='+2'> **Randomized PCA** </font>\n",
        "\n",
        "In this question we want to check the time complexity of finding an approximation of the first $d$ principal components. Also, we want to see how is the performance of it in compare to the original PCA. In order to make this happen there is a stochastic algorithm called *randomized PCA* which has a faster procedure to find the first $d$ principal components.\n",
        "\n",
        "By default, the `svd_solver` parameter of PCA in Scikit-learn is set to `\"auto\"`. It means that it automatically determine to use `\"full\"` or `\"randomized\"` to find the principal components. Base on our text book:\n",
        "\n",
        "\"Scikit-learn uses the randomized PCA algorithm if $max(m, n) > 500$ and `n_components` is an integer smaller than $80\\%$ of $min(m,n)$, or else it uses the full SVD approach\"\n",
        "\n",
        "<font size='+1'>**(a)**</font> For previous question you found $d$ components for each one of the classifiers.This time try to perform PCA without considering the classifier and just by determining the number of components. For the `svd_solver`, this time use both `\"full\"` and `\"randomized\"` arguments separately and compare the results of them. Also compare the running time of `\"full\"` and `\"randomized\"` for each one of the classifiers. Explain your observations. You should perform following steps one-by-one for each classifier:\n",
        "\n",
        "*   Perform PCA for both `\"full\"` and `\"randomized\"`. Repoert the time of performing them.\n",
        "\n",
        "*   For both cases fit the new training data (after dimensionality reduction) to the classifier. Then report the results (Accuracy, F1-score, ...) on test set.\n",
        "\n",
        "<font size='+1'>**(b)**</font> This time consider the $d=10$ and compare the running times for both `\"full\"` and `\"randomized\"` arguments. Explain your observations.\n",
        "\n",
        "<font size='+1'>**(c)**</font> There is something called Incremental PCA (IPCA), explain what is it and in what situations it is useful?\n",
        "\n",
        "<font size='+1'>**(d)**</font> Consider the number of batches equal to $200$ and perform the IPCA."
      ],
      "metadata": {
        "id": "TQc4j8JMWdx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A2:**</font> Your explanations"
      ],
      "metadata": {
        "id": "Z9C3GhsyDVib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "Iob5574QDTvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q3:**</font> <font size='+2'> **Locally Linear Embedding** </font>\n",
        "\n",
        "Locally linear embedding (LLE), is a nonlinear dimensionality reduction algorithm which is categorized as a manifold learning technique.\n",
        "\n",
        "<font size='+1'>**(a)**</font> At first, try to explain how it works by mentioning its optimization objectives.\n",
        "\n",
        "<font size='+1'>**(b)**</font> Now, it's time to implement it and trying to perform your implementation on a swiss roll to see what happens after unrolling. (try to plot your results)\n",
        "The code below make you a swiss roll with $1000$ samples.\n",
        "\n",
        "<font size='+1'>**(c)**</font> Finally use the LLE implementation provided by Scikit-learn to check the results of your implementation. (plot your results)"
      ],
      "metadata": {
        "id": "JfezDIMqW_OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A3:**</font> Your explanations"
      ],
      "metadata": {
        "id": "lhJB7JkmEvTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_swiss_roll\n",
        "\n",
        "X_swiss, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ot2rwJlSW-Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "3gcIzPzZEJm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q4:**</font> <font size='+2'> **t-SNE vs. UMAP ‎️‍🔥** </font>\n",
        "\n",
        "In this question we need the first $5000$ images of Fashion-MNIST dataset. We want to reduce the dimension of these samples down to 2 so we can plot them. Here, we use t-SNE and UMAP to perform these reductions. You can use scatterplot with 10 different colors to demonstrate the class of each instance. After visulaization try to analyze your results and compare them with each other. Is there any pattern in these visualizations?"
      ],
      "metadata": {
        "id": "MlITuQBUiohI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A4:**</font> Your explanations"
      ],
      "metadata": {
        "id": "aOpTYSRME1jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "aVh8hnxZvl3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q5:**</font> <font size='+2'> **Iris** </font>\n",
        "\n",
        "You will take a shortcut and load the Iris dataset from Scikit-learn’s datasets module. Furthermore, you will only select two features, sepal width and petal length, to make the classification task more challenging for illustration purposes"
      ],
      "metadata": {
        "id": "Fd_-f0gjp5bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-4_nATDzrl28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "yoODjVwHrv_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the Iris examples into 50 percent training and 50 percent test data:"
      ],
      "metadata": {
        "id": "srxliDlC4lFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "eRWmkBhYsizR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the training dataset, you now will train three different classifiers:\n",
        "\n",
        "- Logistic regression classifier\n",
        "\n",
        "- Decision tree classifier\n",
        "\n",
        "- k-nearest neighbors classifier\n",
        "\n",
        "you will then evaluate the model performance of each classifier via 10-fold cross-validation on the training dataset before combining them into an ensemble classifier:"
      ],
      "metadata": {
        "id": "0Le3UZmU4oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "iYd5PyN9rxsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q6:**</font> <font size='+2'> **Carseats** </font>\n",
        "\n",
        "#### Ensemble Learning\n",
        "\n",
        "Ensemble learning is a machine learning technique that involves combining the predictions of multiple models to improve the overall performance and accuracy of a system. Instead of relying on a single model to make predictions, ensemble methods use a group of models and aggregate their predictions to achieve better results than any individual model could achieve on its own.\n",
        "\n",
        "The basic idea behind ensemble learning is that by combining the strengths of different models, it is possible to mitigate the weaknesses of each individual model. Ensemble methods are often used to enhance predictive accuracy, reduce overfitting, and improve the robustness of the model.\n",
        "\n",
        "There are several popular ensemble learning techniques, including:\n",
        "\n",
        "**Bagging (Bootstrap Aggregating):** This method involves training multiple instances of the same learning algorithm on different subsets of the training data, typically created by random sampling with replacement. The predictions of these models are then averaged or voted upon to make the final prediction.\n",
        "\n",
        "**Boosting:** Boosting focuses on training a sequence of weak learners, where each subsequent model corrects the errors of its predecessor. Popular boosting algorithms include AdaBoost (Adaptive Boosting) and Gradient Boosting.\n",
        "\n",
        "**Random Forest:** Random Forest is an ensemble method based on bagging. It constructs multiple decision trees during training and combines their predictions through averaging or voting. Each tree in the forest is trained on a random subset of the features.\n",
        "\n",
        "Stacking: Stacking involves training multiple diverse models and using another model (meta-model or blender) to combine their predictions. The predictions of individual models serve as input features for the meta-model.\n",
        "\n",
        "Ensemble learning is a powerful technique that is widely used in various machine learning applications. It is particularly effective when dealing with complex and diverse datasets, as well as when individual models may have different strengths and weaknesses."
      ],
      "metadata": {
        "id": "N0o_08_dpydx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to work with **Carseats** dataset. We want to predict the sales using regression trees and related approaches, treating the response as a quantitative variable."
      ],
      "metadata": {
        "id": "piAQAOuOpijJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load Dataset"
      ],
      "metadata": {
        "id": "1mzLGdm4pwKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz"
      ],
      "metadata": {
        "id": "oym5JLQdcy11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Do preprocess\n",
        "- Split the data set into a training set and a test set."
      ],
      "metadata": {
        "id": "44HOtayap3Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code:"
      ],
      "metadata": {
        "id": "xFVYdiZeqRoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fit a regression tree to the training set. Plot the tree, and interpret\n",
        "the results. What test MSE do you obtain?"
      ],
      "metadata": {
        "id": "ReN9KAYBqUqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "dromxeOMq3Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use the bagging approach in order to analyze this data. What test MSE do you obtain? which variables are most important. visualize them"
      ],
      "metadata": {
        "id": "LAkQPtSfr1JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "MWOPM20ErVMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use random forests to analyze this data. What test MSE do you obtain?  which variables are most important. Describe the effect of m, the number of variables considered at each split, on the error rate obtained."
      ],
      "metadata": {
        "id": "HgADUcGXsSmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "x7ajvS2BrXxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}