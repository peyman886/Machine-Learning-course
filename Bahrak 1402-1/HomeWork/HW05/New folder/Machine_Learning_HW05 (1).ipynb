{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size='+1' color=red>**Attention:**</font> Data cleaning and other parts of preprocessing of data which we covered in the first assignment, is not neccesary all the time but you may need some of them according to task at hand. So we don't explicitly mention them each time. This is your job to figure out when to apply them.\n",
        "\n",
        "<font size='+1' color=red>**Attention 2:**</font> For your implementations always use `random_state=42` so your code would be reproducible."
      ],
      "metadata": {
        "id": "xvYT4kv1TQpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q1:**</font> <font size='+2'> **PCA for Classification** </font>\n",
        "\n",
        "In this question we want to work with the Fashion-MNIST dataset. Fashion-MNIST is a dataset comprising of $28 \\times 28$ grayscale images of $70,000$ fashion products from $10$ categories, with $7,000$ images per category. The training set has $60,000$ images and the test set has $10,000$ images. <br>\n",
        "<font color=red>**Note:**</font> You can download it from any source you want. <br>\n",
        "<font color=red>**Note:**</font> Take first $60,000$ instances of it as the train and the $10,000$ remaining instances as the test set.\n",
        "\n",
        "Using explained varinace ratio and considering a threshold like $95\\%$ you probably know how to choose the right number of dimensions to perform PCA. But, when you are using dimensionality reduction as a preprocessing step for a supervised learning task, it is important to consider the impact of the optimal number of dimensions on the overall performance of the model. Consider the classification task using the dataset at hand. Try to find the best number of components for the PCA with respect to the task. You should use the `RandomForestClassifier`, `KNeighborsClassifier`, `DecisionTreeClassifier`, and `AdaBoostClassifier`. Compare your results (number of dimensions, accuracy, precision, recall, f1-score, and confusion matrix) and explain why the number of dimensions for different models are different. Don't forget to analyze your results. [Hint: you should try to make a pipeline and try to tune the hyperparameters of PCA and your model adjointly.]\n",
        "\n",
        "At the end, perform the hyperparameter tuning but this time without considering the PCA preprocessing step. Compare your results with previous ones."
      ],
      "metadata": {
        "id": "PvVpPcQSYpJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A1:**</font> Your explanations"
      ],
      "metadata": {
        "id": "8rOUtFP1DHAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import Necessary Libraries\n"
      ],
      "metadata": {
        "id": "yuEirALGZoia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "Ryc62iG4ZfJ9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the Dataset"
      ],
      "metadata": {
        "id": "YeFCAEXPZ0BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# from scipy.stats import randint\n",
        "\n",
        "# Load the dataset\n",
        "fashion_mnist = fetch_openml('Fashion-MNIST', version=1)\n",
        "X = fashion_mnist.data\n",
        "y = fashion_mnist.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "metadata": {
        "id": "g1tGNFcUWfVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102b6363-a852-4e88-a70a-d2b0bf822b6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define the Pipelines and Parameters for Grid Search"
      ],
      "metadata": {
        "id": "1aB3QaZJZ4yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = {\n",
        "    'rf': Pipeline([('pca', PCA()), ('classifier', RandomForestClassifier(random_state=42))]),\n",
        "    'knn': Pipeline([('pca', PCA()), ('classifier', KNeighborsClassifier())]),\n",
        "    'dt': Pipeline([('pca', PCA()), ('classifier', DecisionTreeClassifier(random_state=42))]),\n",
        "    'ada': Pipeline([('pca', PCA()), ('classifier', AdaBoostClassifier(random_state=42))])\n",
        "}\n",
        "\n",
        "param_grid = {\n",
        "    'rf': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__n_estimators': [100, 200]},\n",
        "    'knn': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__n_neighbors': [3, 5, 7]},\n",
        "    'dt': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__max_depth': [10, 20, 30]},\n",
        "    'ada': {'pca__n_components': [0.85, 0.90, 0.95], 'classifier__n_estimators': [50, 100]}\n",
        "}\n"
      ],
      "metadata": {
        "id": "Vaj9v_ZVZlIH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train and Evaluate Each Model"
      ],
      "metadata": {
        "id": "8BZ6F525Z-zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    # grid_search = GridSearchCV(pipeline, param_grid[name], cv=5, scoring='accuracy')\n",
        "    grid_search = RandomizedSearchCV(pipeline, param_grid[name], n_iter=5, cv=5, verbose=1, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    predictions = best_model.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        'Best Parameters': grid_search.best_params_,\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Confusion Matrix': confusion_matrix(y_test, predictions)\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "for model, metrics in results.items():\n",
        "    print(f\"Model: {model}\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4iNu_LTaEcQ",
        "outputId": "3f971eee-b2c0-42a8-d196-7fa2b60bfbca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Model: rf\n",
            "Best Parameters: {'pca__n_components': 0.9, 'classifier__n_estimators': 200}\n",
            "Accuracy: 0.8624\n",
            "Precision: 0.8608778165844129\n",
            "Recall: 0.8624\n",
            "F1 Score: 0.8608243789695932\n",
            "Confusion Matrix: [[851   0  14  35   6   4  74   0  16   0]\n",
            " [  5 957   4  24   4   0   4   0   2   0]\n",
            " [ 12   0 794  13 103   0  68   0  10   0]\n",
            " [ 27   3  11 885  26   1  39   0   8   0]\n",
            " [  1   0 106  31 799   1  54   0   8   0]\n",
            " [  0   0   0   0   0 925   0  43   5  27]\n",
            " [156   0 118  32  86   1 581   0  26   0]\n",
            " [  0   0   0   0   0  30   0 927   0  43]\n",
            " [  3   0   2   6   5  11   4   4 963   2]\n",
            " [  0   0   0   0   0  23   0  34   1 942]]\n",
            "\n",
            "\n",
            "Model: knn\n",
            "Best Parameters: {'pca__n_components': 0.95, 'classifier__n_neighbors': 5}\n",
            "Accuracy: 0.8623\n",
            "Precision: 0.8631168655431436\n",
            "Recall: 0.8623000000000001\n",
            "F1 Score: 0.8615934817648251\n",
            "Confusion Matrix: [[852   1  17  17   5   1  98   1   8   0]\n",
            " [  9 969   3  13   4   0   1   0   1   0]\n",
            " [ 19   2 798   9  96   0  75   0   1   0]\n",
            " [ 35   8  14 875  35   0  30   0   3   0]\n",
            " [  1   2 122  27 770   0  74   0   4   0]\n",
            " [  1   0   0   0   0 876   0  66   2  55]\n",
            " [168   1 132  23  77   0 589   0  10   0]\n",
            " [  0   0   0   0   0   5   0 963   0  32]\n",
            " [  4   0   8   5   6   2   8   5 961   1]\n",
            " [  0   0   0   0   0   2   0  27   1 970]]\n",
            "\n",
            "\n",
            "Model: dt\n",
            "Best Parameters: {'pca__n_components': 0.85, 'classifier__max_depth': 20}\n",
            "Accuracy: 0.7753\n",
            "Precision: 0.7769824704072614\n",
            "Recall: 0.7752999999999999\n",
            "F1 Score: 0.7760097294596712\n",
            "Confusion Matrix: [[713   5  26  50  17   4 170   0  14   1]\n",
            " [ 11 928   8  33   9   0  10   0   1   0]\n",
            " [ 34   7 668  22 141   3 113   0  11   1]\n",
            " [ 53  35  26 773  55   1  48   0   8   1]\n",
            " [  8   2 151  47 665   0 116   1   8   2]\n",
            " [  4   1   5   2   1 836   3  81  13  54]\n",
            " [146   2 141  48 113   2 525   2  21   0]\n",
            " [  1   0   0   0   0  68   0 864   6  61]\n",
            " [  9   4  17  10  13  11  27  10 896   3]\n",
            " [  0   0   0   1   1  33   1  79   0 885]]\n",
            "\n",
            "\n",
            "Model: ada\n",
            "Best Parameters: {'pca__n_components': 0.95, 'classifier__n_estimators': 50}\n",
            "Accuracy: 0.5746\n",
            "Precision: 0.5769671741506822\n",
            "Recall: 0.5746\n",
            "F1 Score: 0.5626141335187017\n",
            "Confusion Matrix: [[700   8  57 142  10   3  43   0  37   0]\n",
            " [ 16 390  12 571   5   1   3   0   2   0]\n",
            " [ 29   1 471  23 368   0  76   0  31   1]\n",
            " [ 62 159  11 677  32   2  38   0  19   0]\n",
            " [ 11   1 187 102 591   1  81   0  26   0]\n",
            " [  0   0   0   1   0 621   0 168  28 182]\n",
            " [202   2 279 104 256   1 108   0  48   0]\n",
            " [  0   0   0   0   0 357   0 622   2  19]\n",
            " [ 29   1  32   8  22  26  15   7 852   8]\n",
            " [  1   0   0   1   0 138   0 144   2 714]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q2:**</font> <font size='+2'> **Randomized PCA** </font>\n",
        "\n",
        "In this question we want to check the time complexity of finding an approximation of the first $d$ principal components. Also, we want to see how is the performance of it in compare to the original PCA. In order to make this happen there is a stochastic algorithm called *randomized PCA* which has a faster procedure to find the first $d$ principal components.\n",
        "\n",
        "By default, the `svd_solver` parameter of PCA in Scikit-learn is set to `\"auto\"`. It means that it automatically determine to use `\"full\"` or `\"randomized\"` to find the principal components. Base on our text book:\n",
        "\n",
        "\"Scikit-learn uses the randomized PCA algorithm if $max(m, n) > 500$ and `n_components` is an integer smaller than $80\\%$ of $min(m,n)$, or else it uses the full SVD approach\"\n",
        "\n",
        "<font size='+1'>**(a)**</font> For previous question you found $d$ components for each one of the classifiers.This time try to perform PCA without considering the classifier and just by determining the number of components. For the `svd_solver`, this time use both `\"full\"` and `\"randomized\"` arguments separately and compare the results of them. Also compare the running time of `\"full\"` and `\"randomized\"` for each one of the classifiers. Explain your observations. You should perform following steps one-by-one for each classifier:\n",
        "\n",
        "*   Perform PCA for both `\"full\"` and `\"randomized\"`. Repoert the time of performing them.\n",
        "\n",
        "*   For both cases fit the new training data (after dimensionality reduction) to the classifier. Then report the results (Accuracy, F1-score, ...) on test set.\n",
        "\n",
        "<font size='+1'>**(b)**</font> This time consider the $d=10$ and compare the running times for both `\"full\"` and `\"randomized\"` arguments. Explain your observations.\n",
        "\n",
        "<font size='+1'>**(c)**</font> There is something called Incremental PCA (IPCA), explain what is it and in what situations it is useful?\n",
        "\n",
        "<font size='+1'>**(d)**</font> Consider the number of batches equal to $200$ and perform the IPCA."
      ],
      "metadata": {
        "id": "TQc4j8JMWdx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A2:**</font> Your explanations"
      ],
      "metadata": {
        "id": "Z9C3GhsyDVib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "Iob5574QDTvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q3:**</font> <font size='+2'> **Locally Linear Embedding** </font>\n",
        "\n",
        "Locally linear embedding (LLE), is a nonlinear dimensionality reduction algorithm which is categorized as a manifold learning technique.\n",
        "\n",
        "<font size='+1'>**(a)**</font> At first, try to explain how it works by mentioning its optimization objectives.\n",
        "\n",
        "<font size='+1'>**(b)**</font> Now, it's time to implement it and trying to perform your implementation on a swiss roll to see what happens after unrolling. (try to plot your results)\n",
        "The code below make you a swiss roll with $1000$ samples.\n",
        "\n",
        "<font size='+1'>**(c)**</font> Finally use the LLE implementation provided by Scikit-learn to check the results of your implementation. (plot your results)"
      ],
      "metadata": {
        "id": "JfezDIMqW_OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A3:**</font> Your explanations"
      ],
      "metadata": {
        "id": "lhJB7JkmEvTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_swiss_roll\n",
        "\n",
        "X_swiss, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ot2rwJlSW-Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "3gcIzPzZEJm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q4:**</font> <font size='+2'> **t-SNE vs. UMAP ‎️‍🔥** </font>\n",
        "\n",
        "In this question we need the first $5000$ images of Fashion-MNIST dataset. We want to reduce the dimension of these samples down to 2 so we can plot them. Here, we use t-SNE and UMAP to perform these reductions. You can use scatterplot with 10 different colors to demonstrate the class of each instance. After visulaization try to analyze your results and compare them with each other. Is there any pattern in these visualizations?"
      ],
      "metadata": {
        "id": "MlITuQBUiohI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#8FCF26' size='+2'>**A4:**</font> Your explanations"
      ],
      "metadata": {
        "id": "aOpTYSRME1jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "aVh8hnxZvl3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q5:**</font> <font size='+2'> **Iris** </font>\n",
        "\n",
        "You will take a shortcut and load the Iris dataset from Scikit-learn’s datasets module. Furthermore, you will only select two features, sepal width and petal length, to make the classification task more challenging for illustration purposes"
      ],
      "metadata": {
        "id": "Fd_-f0gjp5bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-4_nATDzrl28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "yoODjVwHrv_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the Iris examples into 50 percent training and 50 percent test data:"
      ],
      "metadata": {
        "id": "srxliDlC4lFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "eRWmkBhYsizR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the training dataset, you now will train three different classifiers:\n",
        "\n",
        "- Logistic regression classifier\n",
        "\n",
        "- Decision tree classifier\n",
        "\n",
        "- k-nearest neighbors classifier\n",
        "\n",
        "you will then evaluate the model performance of each classifier via 10-fold cross-validation on the training dataset before combining them into an ensemble classifier:"
      ],
      "metadata": {
        "id": "0Le3UZmU4oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code"
      ],
      "metadata": {
        "id": "iYd5PyN9rxsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#D61E85' size='+3'>**Q6:**</font> <font size='+2'> **Carseats** </font>\n",
        "\n",
        "#### Ensemble Learning\n",
        "\n",
        "Ensemble learning is a machine learning technique that involves combining the predictions of multiple models to improve the overall performance and accuracy of a system. Instead of relying on a single model to make predictions, ensemble methods use a group of models and aggregate their predictions to achieve better results than any individual model could achieve on its own.\n",
        "\n",
        "The basic idea behind ensemble learning is that by combining the strengths of different models, it is possible to mitigate the weaknesses of each individual model. Ensemble methods are often used to enhance predictive accuracy, reduce overfitting, and improve the robustness of the model.\n",
        "\n",
        "There are several popular ensemble learning techniques, including:\n",
        "\n",
        "**Bagging (Bootstrap Aggregating):** This method involves training multiple instances of the same learning algorithm on different subsets of the training data, typically created by random sampling with replacement. The predictions of these models are then averaged or voted upon to make the final prediction.\n",
        "\n",
        "**Boosting:** Boosting focuses on training a sequence of weak learners, where each subsequent model corrects the errors of its predecessor. Popular boosting algorithms include AdaBoost (Adaptive Boosting) and Gradient Boosting.\n",
        "\n",
        "**Random Forest:** Random Forest is an ensemble method based on bagging. It constructs multiple decision trees during training and combines their predictions through averaging or voting. Each tree in the forest is trained on a random subset of the features.\n",
        "\n",
        "Stacking: Stacking involves training multiple diverse models and using another model (meta-model or blender) to combine their predictions. The predictions of individual models serve as input features for the meta-model.\n",
        "\n",
        "Ensemble learning is a powerful technique that is widely used in various machine learning applications. It is particularly effective when dealing with complex and diverse datasets, as well as when individual models may have different strengths and weaknesses."
      ],
      "metadata": {
        "id": "N0o_08_dpydx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to work with **Carseats** dataset. We want to predict the sales using regression trees and related approaches, treating the response as a quantitative variable."
      ],
      "metadata": {
        "id": "piAQAOuOpijJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load Dataset"
      ],
      "metadata": {
        "id": "1mzLGdm4pwKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz"
      ],
      "metadata": {
        "id": "oym5JLQdcy11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Do preprocess\n",
        "- Split the data set into a training set and a test set."
      ],
      "metadata": {
        "id": "44HOtayap3Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code:"
      ],
      "metadata": {
        "id": "xFVYdiZeqRoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fit a regression tree to the training set. Plot the tree, and interpret\n",
        "the results. What test MSE do you obtain?"
      ],
      "metadata": {
        "id": "ReN9KAYBqUqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "dromxeOMq3Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use the bagging approach in order to analyze this data. What test MSE do you obtain? which variables are most important. visualize them"
      ],
      "metadata": {
        "id": "LAkQPtSfr1JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "MWOPM20ErVMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use random forests to analyze this data. What test MSE do you obtain?  which variables are most important. Describe the effect of m, the number of variables considered at each split, on the error rate obtained."
      ],
      "metadata": {
        "id": "HgADUcGXsSmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "x7ajvS2BrXxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}